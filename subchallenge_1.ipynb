{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Methods:\n",
    "\n",
    "1) Sample Mean\n",
    "\n",
    "2) SoftImpute\n",
    "\n",
    "3) IterativeSVD\n",
    "\n",
    "4) MICE\n",
    "\n",
    "5) Matrix Factorisation\n",
    "\n",
    "6) NuclearNormMinimization\n",
    "\n",
    "7) Autoencoder with adapted objective\n",
    "\n",
    "8) PCA + Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# training data\n",
    "dfs = [pd.read_csv(\"./dream_proteogenomics_challenge_dataset/sub_challenge_1/data_obs_{}.txt\".format(i), \n",
    "                header=0, index_col=0, sep=\"\\t\") for i in range(1, 11)]\n",
    "\n",
    "# ground truth\n",
    "ground_truth_table = pd.read_csv(\"./dream_proteogenomics_challenge_dataset/sub_challenge_1/data_true.txt\", \n",
    "                header=0, index_col=0, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conver from data frame ot numpy array\n",
    "datas = [df.values for df in dfs]\n",
    "ground_truth = ground_truth_table.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensionality of data\n",
    "num_samples, num_features = ground_truth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# root mean squared error with three masks\n",
    "def rmse (original_data, y_pred, y_true=ground_truth): \n",
    "    # rsme prediction and ground truth\n",
    "    rmse_no_mask = np.sqrt(mse(y_true, y_pred))\n",
    "    \n",
    "    # ignore all zeros in the ground truth data\n",
    "    no_zeros = y_true > 0\n",
    "    rmse_no_zeros = np.sqrt(mse(y_true[no_zeros], y_pred[no_zeros]))\n",
    "    \n",
    "    # ignore zeros and only consider data that was originally nan in the training data\n",
    "    nan_no_zeros = np.isnan(original_data) & (y_true > 0)\n",
    "    rmse_nan_no_zeros = np.sqrt(mse(y_true[nan_no_zeros], y_pred[nan_no_zeros]))\n",
    "    \n",
    "    # concatenate all three results\n",
    "    return np.array([rmse_no_mask, rmse_no_zeros, rmse_nan_no_zeros])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.gpuarray): Could not initialize pygpu, support disabled\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/david/miniconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 179, in <module>\n",
      "    use(config.device)\n",
      "  File \"/home/david/miniconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 166, in use\n",
      "    init_dev(device, preallocate=preallocate)\n",
      "  File \"/home/david/miniconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 65, in init_dev\n",
      "    sched=config.gpuarray.sched)\n",
      "  File \"pygpu/gpuarray.pyx\", line 634, in pygpu.gpuarray.init (pygpu/gpuarray.c:9424)\n",
      "  File \"pygpu/gpuarray.pyx\", line 584, in pygpu.gpuarray.pygpu_init (pygpu/gpuarray.c:9115)\n",
      "  File \"pygpu/gpuarray.pyx\", line 1057, in pygpu.gpuarray.GpuContext.__cinit__ (pygpu/gpuarray.c:13417)\n",
      "GpuArrayException: No cuda device available\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imputation methods\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from fancyimpute import SimpleFill, KNN, SoftImpute, IterativeSVD, MICE, MatrixFactorization, NuclearNormMinimization\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.objectives import binary_crossentropy, mean_squared_error\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "# impute with sample mean\n",
    "def sample_mean(data, **kwargs):\n",
    "    fill = SimpleFill(fill_method=\"mean\")\n",
    "    return fill.complete(data)\n",
    "\n",
    "# impute with knn-3\n",
    "def knn_3(data, **kwargs):\n",
    "    fill = KNN(k=3, verbose=0)\n",
    "    return fill.complete(data)\n",
    "\n",
    "# impute with knn-5\n",
    "def knn_5(data, **kwargs):\n",
    "    fill = KNN(k=5, verbose=0)\n",
    "    return fill.complete(data)\n",
    "\n",
    "# knn for any k\n",
    "def knn(data, k, **kwargs):\n",
    "    fill = KNN(k=k, verbose=0)\n",
    "    return fill.complete(data)\n",
    "\n",
    "# softimpute from fancyimpute package\n",
    "def soft_impute(data, **kwargs):\n",
    "    fill = SoftImpute(verbose=0)\n",
    "    return fill.complete(data)\n",
    "\n",
    "# iterativeSVD from fancy impute package\n",
    "def iterative_SVD(data, **kwargs):\n",
    "    fill = IterativeSVD(verbose=0)\n",
    "    return fill.complete(data)\n",
    "\n",
    "# MICE for fancyimpute package\n",
    "def mice(data, **kwargs):\n",
    "    fill = MICE(verbose=0)\n",
    "    return fill.complete(data)\n",
    "\n",
    "# modified autoencoder that does not propagate error from missing values\n",
    "def modified_autoencoder(data, num_hidden=[32], dropout=0.1, **kwargs):\n",
    "    \n",
    "    # to normalise the data we must impute \n",
    "    mean_imputer = SimpleFill(fill_method=\"mean\")\n",
    "    data_imputed = mean_imputer.complete(data)\n",
    "    \n",
    "    # standard scaling for normalisation\n",
    "    standard_scaler = StandardScaler()\n",
    "    data_imputed_and_scaled = standard_scaler.fit_transform(data_imputed)\n",
    "    \n",
    "    # replace all missing values with 0 so they do not contribute to input\n",
    "    data_imputed_and_scaled[np.isnan(data)] = 0\n",
    "    \n",
    "    # maintain nan in target data so we know which outputs should not prodice any error\n",
    "    data_scaled_with_nan = np.array([[data_imputed_and_scaled[i, j] if ~np.isnan(data[i, j]) else np.nan\n",
    "                                     for j in range(num_features)] for i in range(num_samples)])\n",
    "    \n",
    "    # custom MSE that only produces error on non-nan terms\n",
    "    def custom_MSE(y_true, y_pred):\n",
    "    \n",
    "        y_true = K.flatten(y_true)\n",
    "        y_pred = K.flatten(y_pred)\n",
    "\n",
    "        # mask for targets that are not nan\n",
    "        mask = ~tf.is_nan(y_true)\n",
    "\n",
    "        # apply the mask to targets and output of network and then compute MSE with what remains\n",
    "        y_true = tf.boolean_mask(tensor=y_true, mask=mask)\n",
    "        y_pred = tf.boolean_mask(tensor=y_pred, mask=mask)\n",
    "\n",
    "        return mean_squared_error(y_true, y_pred)\n",
    "\n",
    "    \n",
    "    # construct model\n",
    "    x = Input(shape=(num_features,))\n",
    "    \n",
    "    # first fully connected layer layer\n",
    "    y = Dense(num_hidden[0], activation=\"relu\")(x)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Dropout(dropout)(y)\n",
    "\n",
    "    # all remaining fully connected layers\n",
    "    for h in num_hidden[1:] + num_hidden[-2::-1]:\n",
    "        y = Dense(h, activation=\"relu\")(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Dropout(dropout)(y)\n",
    "    \n",
    "    # output -- no activation function \n",
    "    y = Dense(num_features, activation=\"linear\")(y)\n",
    "    autoencoder = Model(x, y)\n",
    "    autoencoder.compile(optimizer=\"adam\", loss=custom_binary_crossentropy)\n",
    "    early_stopping = EarlyStopping(monitor=\"loss\", patience=1000, min_delta=0)\n",
    "    tqdm = TQDMNotebookCallback(leave_inner=False, leave_outer=True)\n",
    "    # train model\n",
    "    autoencoder.fit(data_imputed_and_scaled, data_scaled_with_nan, \n",
    "                    verbose=0, epochs=10000, batch_size=100, callbacks=[early_stopping, tqdm])\n",
    "    # predict data\n",
    "    prediction = autoencoder.predict(data_imputed_and_scaled)\n",
    "    \n",
    "    # reverse normalise and return\n",
    "    return standard_scaler.inverse_transform(prediction)\n",
    "\n",
    "# PCA and then autoencoder\n",
    "def pca_autoencoder(data, num_hidden=[32], dropout=0.1, pca_dim=64, **kwargs):\n",
    "    \n",
    "    #construct model\n",
    "    x = Input(shape=(pca_dim,))\n",
    "    y = Dropout(1e-8)(x)\n",
    "    for h in num_hidden + num_hidden[-2::-1]:\n",
    "        y = Dense(h, activation=\"relu\")(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Dropout(dropout)(y)\n",
    "    y = Dense(pca_dim)(y)\n",
    "    \n",
    "    autoencoder = Model(x, y)\n",
    "    autoencoder.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    \n",
    "    \n",
    "    # project with pca\n",
    "    mean_imputer = SimpleFill()\n",
    "    data_imputed = mean_imputer.complete(data)\n",
    "    pca = PCA(n_components=pca_dim)\n",
    "    data_transformed = pca.fit_transform(data_imputed)\n",
    "    early_stopping = EarlyStopping(monitor=\"loss\", patience=100, min_delta=0)\n",
    "    tqdm = TQDMNotebookCallback(leave_inner=False, leave_outer=True)\n",
    "    autoencoder.fit(data_transformed, data_transformed, \n",
    "                    verbose=0, epochs=10000, batch_size=100, callbacks=[early_stopping, tqdm])\n",
    "    \n",
    "    prediction = autoencoder.predict(data_transformed)\n",
    "    \n",
    "    return pca.inverse_transform(prediction)\n",
    "\n",
    "imputation_methods = [sample_mean, knn_3, knn_5, soft_impute, iterative_SVD, mice,\n",
    "                     modified_autoencoder, pca_autoencoder]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute mean rmse across a number of repreats\n",
    "def mean_rmse(data, imputation_method, num_repeats=1, **kwargs):\n",
    "    \n",
    "    imputed_predictions = [imputation_method(data, **kwargs) for i in range(num_repeats)]\n",
    "    \n",
    "    rmses = np.array([rmse(data, imputed_prediction) for imputed_prediction in imputed_predictions])\n",
    "\n",
    "    return np.array([rmses.mean(axis=0), rmses.std(axis=0) / np.sqrt(num_repeats)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b3dd79a81aeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m rmses = np.array([[mean_rmse(data, imputation_method, num_repeats=1) for data in datas] \n\u001b[0;32m----> 2\u001b[0;31m                   for imputation_method in imputation_methods])\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-d5bd9a25cf78>\u001b[0m in \u001b[0;36mmean_rmse\u001b[0;34m(data, imputation_method, num_repeats, **kwargs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmean_rmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimputation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimputed_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimputation_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_repeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrmses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimputed_prediction\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimputed_prediction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimputed_predictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-3777334e1cac>\u001b[0m in \u001b[0;36msoft_impute\u001b[0;34m(data, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoft_impute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mfill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSoftImpute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0miterative_SVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/fancyimpute/solver.pyc\u001b[0m in \u001b[0;36mcomplete\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mcompleted\u001b[0m \u001b[0mmatrix\u001b[0m \u001b[0mwithout\u001b[0m \u001b[0many\u001b[0m \u001b[0mNaNs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mimputations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_imputations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimputations\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimputations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/fancyimpute/solver.pyc\u001b[0m in \u001b[0;36mmultiple_imputations\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mGenerate\u001b[0m \u001b[0mmultiple\u001b[0m \u001b[0mimputations\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mincomplete\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \"\"\"\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_imputation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_imputations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/fancyimpute/solver.pyc\u001b[0m in \u001b[0;36msingle_imputation\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    182\u001b[0m                     type(X_filled)))\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m         \u001b[0mX_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_filled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             raise TypeError(\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/fancyimpute/soft_impute.pyc\u001b[0m in \u001b[0;36msolve\u001b[0;34m(self, X, missing_mask)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mX_filled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0mshrinkage_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 max_rank=self.max_rank)\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mX_reconstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_reconstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/fancyimpute/soft_impute.pyc\u001b[0m in \u001b[0;36m_svd_step\u001b[0;34m(self, X, shrinkage_value, max_rank)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 compute_uv=True)\n\u001b[0m\u001b[1;32m    119\u001b[0m         \u001b[0ms_thresh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mshrinkage_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mrank\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms_thresh\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/numpy/linalg/linalg.pyc\u001b[0m in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0msignature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'D->DdD'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misComplexType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'd->ddd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_realType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# iterate over all training data and imputation methods and compute mean rmse for num repeats\n",
    "rmses = np.array([[mean_rmse(data, imputation_method, num_repeats=1) for data in datas] \n",
    "                  for imputation_method in imputation_methods])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 10, 2, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmses.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.7597732 ,  2.76309638,  2.75672952,  2.75636435,  2.76485654,\n",
       "         2.76196537,  2.76340014,  2.76509131,  2.75448701,  2.77039009],\n",
       "       [ 0.38680467,  0.38285721,  0.38561355,  0.38344047,  0.38623934,\n",
       "         0.38712029,  0.38773104,  0.38611536,  0.38358458,  0.384058  ],\n",
       "       [ 0.37879539,  0.3745887 ,  0.37762995,  0.37547017,  0.3781731 ,\n",
       "         0.37907788,  0.37988369,  0.37869369,  0.37573435,  0.37556994],\n",
       "       [ 0.61878808,  0.61355408,  0.61921208,  0.6157398 ,  0.62097853,\n",
       "         0.61875009,  0.61796618,  0.62030517,  0.61419182,  0.61377519],\n",
       "       [ 0.42367615,  0.57823638,  0.46558489,  0.53764899,  0.44285712,\n",
       "         0.63407889,  0.60058502,  0.66988099,  0.44737126,  0.41292973],\n",
       "       [ 0.47535888,  0.47287617,  0.47466673,  0.47235295,  0.47387391,\n",
       "         0.47581249,  0.47394509,  0.47590199,  0.47230753,  0.47212648],\n",
       "       [ 0.91146462,  0.94572842,  0.96605951,  0.97682642,  0.97955146,\n",
       "         0.92247776,  1.01936476,  0.95515879,  1.02395664,  0.88804162],\n",
       "       [ 1.90085293,  1.90039899,  1.86990987,  1.88047081,  1.91224393,\n",
       "         1.90223169,  1.86957211,  1.88551191,  1.88096438,  1.90364174]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmses[:,:,0, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(X=rmses[:,:,0,0], fname=\"rmses_no_mask_repeat.csv\", delimiter=\",\")\n",
    "np.savetxt(X=rmses[:,:,0,1], fname=\"rmses_no_zeros_repeat.csv\", delimiter=\",\")\n",
    "np.savetxt(X=rmses[:,:,0,2], fname=\"rmses_nan_no_zeros_repeat.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print \"done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_mask_df = pd.read_csv(\"rmses_no_mask.csv\", delimiter=\",\", header=None)\n",
    "no_mask_df.index = [\"mean\", \"knn-3\", \"knn-5\", \"SoftImpute\", \"IterativeSVD\", \"MICE\", \"Autoencoder\", \"PCA + Autoencoder\"]\n",
    "no_mask_df.columns = [\"training data {}\".format(i) for i in range (1, 11)]\n",
    "no_mask_df[\"mean\"] = no_mask_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   training data 1  training data 2  training data 3  \\\n",
      "mean                      7.133199         7.132806         7.132971   \n",
      "knn-3                     7.026231         7.026359         7.026145   \n",
      "knn-5                     7.025893         7.026301         7.026007   \n",
      "SoftImpute                6.884854         6.884924         6.884749   \n",
      "IterativeSVD              7.013616         7.009545         7.011087   \n",
      "MICE                      7.024887         7.025130         7.024706   \n",
      "Autoencoder               7.030034         7.040505         7.019529   \n",
      "PCA + Autoencoder         7.118199         7.117698         7.117205   \n",
      "\n",
      "                   training data 4  training data 5  training data 6  \\\n",
      "mean                      7.131805         7.132475         7.132670   \n",
      "knn-3                     7.026199         7.025655         7.026029   \n",
      "knn-5                     7.026201         7.025750         7.025946   \n",
      "SoftImpute                6.884928         6.884682         6.884909   \n",
      "IterativeSVD              7.008194         7.013022         7.003828   \n",
      "MICE                      7.024739         7.024567         7.024863   \n",
      "Autoencoder               7.045570         7.037380         7.039291   \n",
      "PCA + Autoencoder         7.117362         7.114353         7.113515   \n",
      "\n",
      "                   training data 7  training data 8  training data 9  \\\n",
      "mean                      7.131543         7.133563         7.132111   \n",
      "knn-3                     7.026531         7.026112         7.026387   \n",
      "knn-5                     7.026288         7.025928         7.026471   \n",
      "SoftImpute                6.884753         6.884583         6.884948   \n",
      "IterativeSVD              7.006277         7.006886         7.011981   \n",
      "MICE                      7.024727         7.024875         7.024837   \n",
      "Autoencoder               7.035893         7.044125         7.035325   \n",
      "PCA + Autoencoder         7.117044         7.113870         7.117584   \n",
      "\n",
      "                   training data 10      mean  \n",
      "mean                       7.134495  7.132764  \n",
      "knn-3                      7.026343  7.026199  \n",
      "knn-5                      7.026064  7.026085  \n",
      "SoftImpute                 6.884920  6.884825  \n",
      "IterativeSVD               7.013721  7.009816  \n",
      "MICE                       7.025084  7.024841  \n",
      "Autoencoder                7.042378  7.037003  \n",
      "PCA + Autoencoder          7.115483  7.116231  \n"
     ]
    }
   ],
   "source": [
    "print no_mask_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_zeros_df = pd.read_csv(\"rmses_no_zero.csv\", delimiter=\",\", header=None)\n",
    "mask_zeros_df.index = [\"mean\", \"knn-3\", \"knn-5\", \"SoftImpute\", \"IterativeSVD\", \"MICE\", \"Autoencoder\", \"PCA + Autoencoder\"]\n",
    "mask_zeros_df.columns = [\"training data {}\".format(i) for i in range (1, 11)]\n",
    "mask_zeros_df[\"mean\"] = mask_zeros_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   training data 1  training data 2  training data 3  \\\n",
      "mean                      1.302482         1.303398         1.299847   \n",
      "knn-3                     0.182553         0.180600         0.181824   \n",
      "knn-5                     0.178773         0.176700         0.178059   \n",
      "SoftImpute                0.292039         0.289424         0.291970   \n",
      "IterativeSVD              0.199955         0.272764         0.219532   \n",
      "MICE                      0.224463         0.223010         0.223827   \n",
      "Autoencoder               0.460790         0.453687         0.452376   \n",
      "PCA + Autoencoder         1.028992         1.020798         1.003990   \n",
      "\n",
      "                   training data 4  training data 5  training data 6  \\\n",
      "mean                      1.301221         1.305107         1.302762   \n",
      "knn-3                     0.181014         0.182318         0.182597   \n",
      "knn-5                     0.177251         0.178511         0.178803   \n",
      "SoftImpute                0.290678         0.293123         0.291852   \n",
      "IterativeSVD              0.253813         0.209044         0.299082   \n",
      "MICE                      0.223066         0.223713         0.224430   \n",
      "Autoencoder               0.455544         0.451820         0.454239   \n",
      "PCA + Autoencoder         1.017061         1.020421         1.003361   \n",
      "\n",
      "                   training data 7  training data 8  training data 9  \\\n",
      "mean                      1.304245         1.305474         1.297571   \n",
      "knn-3                     0.182998         0.182295         0.180697   \n",
      "knn-5                     0.179294         0.178791         0.176999   \n",
      "SoftImpute                0.291662         0.292863         0.289331   \n",
      "IterativeSVD              0.283459         0.316269         0.210746   \n",
      "MICE                      0.223567         0.224732         0.222423   \n",
      "Autoencoder               0.458339         0.456140         0.458686   \n",
      "PCA + Autoencoder         1.035487         0.972678         0.985194   \n",
      "\n",
      "                   training data 10      mean  \n",
      "mean                       1.307899  1.303001  \n",
      "knn-3                      0.181313  0.181821  \n",
      "knn-5                      0.177306  0.178049  \n",
      "SoftImpute                 0.289763  0.291270  \n",
      "IterativeSVD               0.194944  0.245961  \n",
      "MICE                       0.222995  0.223623  \n",
      "Autoencoder                0.462437  0.456406  \n",
      "PCA + Autoencoder          1.022777  1.011076  \n"
     ]
    }
   ],
   "source": [
    "print mask_zeros_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_nan_zeros_df = pd.read_csv(\"rmses_nan_no_zero.csv\", delimiter=\",\", header=None)\n",
    "mask_nan_zeros_df.index = [\"mean\", \"knn-3\", \"knn-5\", \"SoftImpute\", \"IterativeSVD\", \"MICE\", \"Autoencoder\", \"PCA + Autoencoder\"]\n",
    "mask_nan_zeros_df.columns = [\"training data {}\".format(i) for i in range (1, 11)]\n",
    "mask_nan_zeros_df[\"mean\"] = mask_nan_zeros_df.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   training data 1  training data 2  training data 3  \\\n",
      "mean                      2.759773         2.763096         2.756730   \n",
      "knn-3                     0.386805         0.382857         0.385614   \n",
      "knn-5                     0.378795         0.374589         0.377630   \n",
      "SoftImpute                0.618788         0.613554         0.619212   \n",
      "IterativeSVD              0.423676         0.578236         0.465585   \n",
      "MICE                      0.475537         0.472904         0.474732   \n",
      "Autoencoder               0.498770         0.478248         0.496549   \n",
      "PCA + Autoencoder         1.297658         1.307910         1.301271   \n",
      "\n",
      "                   training data 4  training data 5  training data 6  \\\n",
      "mean                      2.756364         2.764857         2.761965   \n",
      "knn-3                     0.383440         0.386239         0.387120   \n",
      "knn-5                     0.375470         0.378173         0.379078   \n",
      "SoftImpute                0.615740         0.620979         0.618750   \n",
      "IterativeSVD              0.537649         0.442857         0.634079   \n",
      "MICE                      0.472349         0.474027         0.475589   \n",
      "Autoencoder               0.494030         0.487866         0.487199   \n",
      "PCA + Autoencoder         1.293515         1.294030         1.281248   \n",
      "\n",
      "                   training data 7  training data 8  training data 9  \\\n",
      "mean                      2.763400         2.765091         2.754487   \n",
      "knn-3                     0.387731         0.386115         0.383585   \n",
      "knn-5                     0.379884         0.378694         0.375734   \n",
      "SoftImpute                0.617966         0.620305         0.614192   \n",
      "IterativeSVD              0.600585         0.669881         0.447371   \n",
      "MICE                      0.474107         0.475911         0.471840   \n",
      "Autoencoder               0.482599         0.491438         0.484820   \n",
      "PCA + Autoencoder         1.291835         1.270748         1.260291   \n",
      "\n",
      "                   training data 10      mean  \n",
      "mean                       2.770390  2.761615  \n",
      "knn-3                      0.384058  0.385356  \n",
      "knn-5                      0.375570  0.377362  \n",
      "SoftImpute                 0.613775  0.617326  \n",
      "IterativeSVD               0.412930  0.521285  \n",
      "MICE                       0.472236  0.473923  \n",
      "Autoencoder                0.480193  0.488171  \n",
      "PCA + Autoencoder          1.282852  1.288136  \n"
     ]
    }
   ],
   "source": [
    "print mask_nan_zeros_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
