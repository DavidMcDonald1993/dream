{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data\n",
      "Computing rmses\n",
      "Building linear model\n",
      "Appending training matrices for linear model\n",
      "Fitting linear model\n",
      "Building deep non linear regression model\n",
      "Training deep non linear regression model\n",
      "Building deep non linear regression model\n",
      "Training deep non linear regression model\n",
      "Building deep non linear regression model\n",
      "Training deep non linear regression model\n",
      "Reshaping training matrices for xgboost\n",
      "Training xgboost\n",
      "Reshaping training matrices for xgboost\n",
      "Training xgboost\n",
      "Reshaping training matrices for xgboost\n",
      "Training xgboost\n",
      "Reshaping training matrices for xgboost\n",
      "Training xgboost\n",
      "fitting adaboost with linear\n",
      "predicting\n",
      "fitting adaboost with lasso\n",
      "predicting\n",
      "fitting adaboost with elastic_net\n",
      "predicting\n",
      "fitting adaboost with bayesian_ridge\n",
      "predicting\n",
      "RMSES:\n",
      "[ 0.81519505  1.00065066  0.98832418  1.36924023  0.89537024  0.89486129\n",
      "  0.89683627  1.01897955  0.92512599  1.00366256  1.01468102  0.92704522]\n",
      "Saving rmses to ../results/subchallenge_2/linear_regression_sigmoid_256_relu_256_tanh_256_xgboost_4_xgboost_6_xgboost_10_xgboost_no_limit_adaboost_linear_adaboost_lasso_adaboost_elastic_net_adaboost_bayesian_ridge.csv\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "from keras.layers import Input, Dense, Concatenate, Dropout, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from fancyimpute import KNN\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, ElasticNet, BayesianRidge\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "def preprocess_data(holdout=0.2):\n",
    "    \n",
    "    # import data for breast cancer datasets\n",
    "    cna_data_frame = pd.read_csv(\"../data/sub_challenge_2_3/breast_cancer_dataset/retrospective_breast_CNA_median_sort_common_gene_16884.txt\", \n",
    "                    header=0, index_col=0, sep=\"\\t\")\n",
    "    rna_data_frame = pd.read_csv(\"../data/sub_challenge_2_3/breast_cancer_dataset/retrospective_breast_rna_seq_sort_common_gene_15115.txt\", \n",
    "                    header=0, index_col=0, sep=\"\\t\")\n",
    "    proteome_data_frame = pd.read_csv(\"../data/sub_challenge_2_3/breast_cancer_dataset/retrospective_breast_proteome_filtered.txt\", \n",
    "                    header=0, index_col=0, sep=\"\\t\")\n",
    "\n",
    "    # convert rna data to numpy array to impute\n",
    "    rna_data = rna_data_frame.values\n",
    "\n",
    "    # use knn to fill in missing values in rna data\n",
    "    knn = KNN(k=5, verbose=0)\n",
    "    rna_data = knn.complete(rna_data)\n",
    "\n",
    "    # proteome data also has missing values, but I am ignoring rows with missing values for now\n",
    "    # proteome_data = knn.complete(proteome_data)\n",
    "\n",
    "    # update rna data frame with imputed data\n",
    "    rna_data_frame = pd.DataFrame(rna_data, index = rna_data_frame.index, columns = rna_data_frame.columns)\n",
    "\n",
    "    # find common proteins and patients across all datasets\n",
    "    proteins = proteome_data_frame.index.intersection(cna_data_frame.index).intersection(rna_data_frame.index)\n",
    "    patients = proteome_data_frame.columns.intersection(cna_data_frame.columns).intersection(rna_data_frame.columns)\n",
    "\n",
    "    # locate common data and return as numpy array\n",
    "    cna_data = cna_data_frame.loc[proteins, patients].values\n",
    "    rna_data = rna_data_frame.loc[proteins, patients].values\n",
    "    proteome_data = proteome_data_frame.loc[proteins, patients].values\n",
    "\n",
    "    # masks for proteins with complete data and with missing value\n",
    "    complete_proteins = proteins[~(np.isnan(proteome_data).any(axis=1))]\n",
    "    missing_value_proteins = proteins[np.isnan(proteome_data).any(axis=1)]\n",
    "\n",
    "    # use complete data as training/validation data\n",
    "    cna_data = cna_data_frame.loc[complete_proteins, patients].values\n",
    "    rna_data = rna_data_frame.loc[complete_proteins, patients].values\n",
    "    proteome_data = proteome_data_frame.loc[complete_proteins, patients].values\n",
    "\n",
    "    # standard scaling\n",
    "    cna_scaler = StandardScaler()\n",
    "    rna_scaler = StandardScaler()\n",
    "    proteome_scaler = StandardScaler()\n",
    "\n",
    "    cna_data = cna_scaler.fit_transform(cna_data)\n",
    "    rna_data = rna_scaler.fit_transform(rna_data)\n",
    "    proteome_data = proteome_scaler.fit_transform(proteome_data)\n",
    "    \n",
    "    # mask of training/validation data\n",
    "    mask = np.random.rand(cna_data.shape[0]) < holdout\n",
    "    \n",
    "    cna_training_data = cna_data[~mask]\n",
    "    rna_training_data = rna_data[~mask]\n",
    "    proteome_training_data = proteome_data[~mask]\n",
    "    \n",
    "    cna_validation_data = cna_data[mask]\n",
    "    rna_validation_data = rna_data[mask]\n",
    "    proteome_validation_data = proteome_data[mask]\n",
    "    \n",
    "    # return training data scalers for inverse scaling\n",
    "    return cna_training_data, rna_training_data, proteome_training_data, cna_validation_data, rna_validation_data, proteome_validation_data, cna_scaler, rna_scaler, proteome_scaler\n",
    "\n",
    "def rmse (y_pred, y_true): \n",
    "    # rsme prediction and ground truth\n",
    "    return np.sqrt(mse(y_true, y_pred))\n",
    "\n",
    "# compute mean rmse across a number of repreats\n",
    "def mean_rmse(cna_training_data, rna_training_data, proteome_training_data, \n",
    "            cna_validation_data, rna_validation_data, proteome_validation_data,\n",
    "              regression_method, num_repeats=1, **kwargs):\n",
    "    \n",
    "    abundance_predictions = [regression_method(cna_training_data, rna_training_data, proteome_training_data, \n",
    "                                               cna_validation_data, rna_validation_data, **kwargs) \n",
    "                             for i in range(num_repeats)]\n",
    "    \n",
    "    rmses = np.array([rmse(abundance_prediction, proteome_validation_data) \n",
    "                      for abundance_prediction in abundance_predictions])\n",
    "\n",
    "    return rmses.mean(axis=0)\n",
    "\n",
    "def linear_regression(cna_training_data, rna_training_data, proteome_training_data, \n",
    "                                         cna_validation_data, rna_validation_data,**kwargs):\n",
    "    \n",
    "    print \"Building linear model\"\n",
    "    \n",
    "    linear_model = LinearRegression()\n",
    "    \n",
    "    print \"Appending training matrices for linear model\"\n",
    "    \n",
    "    # append data for linear regression\n",
    "    cna_rna_training_data_append = np.append(cna_training_data, rna_training_data, axis=1)\n",
    "    \n",
    "    print \"Fitting linear model\"\n",
    "    \n",
    "    linear_model.fit(cna_rna_training_data_append, proteome_training_data)\n",
    "    \n",
    "    # predictions\n",
    "    cna_rna_validation_data_append = np.append(cna_validation_data, rna_validation_data, axis=1)\n",
    "    \n",
    "    abundance_predictions = linear_model.predict(cna_rna_validation_data_append)\n",
    "    \n",
    "    return abundance_predictions\n",
    "\n",
    "# construct model\n",
    "def build_deep_regression_model(num_samples, num_hidden, dropout, activation, reg):\n",
    "    \n",
    "    regulariser = l2(reg)\n",
    "\n",
    "    cna = Input(shape=(num_samples,))\n",
    "    rna = Input(shape=(num_samples,))\n",
    "\n",
    "    y = Concatenate()([cna, rna])\n",
    "\n",
    "    for h in num_hidden:\n",
    "        y = Dense(h, activation=activation, kernel_regularizer=regulariser)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Dropout(dropout)(y)\n",
    "\n",
    "    y = Dense(num_samples, kernel_regularizer=regulariser)(y)\n",
    "\n",
    "    deep_non_linear_regression_model = Model([cna, rna], y)\n",
    "    deep_non_linear_regression_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    \n",
    "    return deep_non_linear_regression_model\n",
    "\n",
    "def deep_non_linear_regression(cna_training_data, rna_training_data, proteome_training_data,\n",
    "                               cna_validation_data, rna_validation_data,\n",
    "                               num_hidden=[128], dropout=0.1, activation=\"relu\", reg=1e-3, **kwargs):\n",
    "    \n",
    "    print \"Building deep non linear regression model\"\n",
    "    \n",
    "    # dimensionality of data\n",
    "    num_proteins, num_samples = cna_training_data.shape\n",
    "     \n",
    "    # build model\n",
    "    regression_model = build_deep_regression_model(num_samples, num_hidden, dropout, activation, reg)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor=\"loss\", patience=1000, min_delta=0, )\n",
    "    \n",
    "    print \"Training deep non linear regression model\"\n",
    "\n",
    "    # train model\n",
    "    regression_model.fit([cna_training_data, rna_training_data], proteome_training_data, \n",
    "                         verbose=0, epochs=10000, batch_size=128, shuffle=True, validation_split=0.0,\n",
    "                         callbacks=[early_stopping])\n",
    "\n",
    "    # protein abundance predictions\n",
    "    abundance_predictions = regression_model.predict([cna_validation_data, rna_validation_data])\n",
    "    \n",
    "    return abundance_predictions\n",
    "\n",
    "def xgboost(cna_training_data, rna_training_data, proteome_training_data, \n",
    "            cna_validation_data, rna_validation_data,**kwargs):\n",
    "    \n",
    "    print \"Reshaping training matrices for xgboost\"\n",
    "    \n",
    "    # reshape to columns because xgboost regression can only have single numbers as labels\n",
    "    cna_training_data_shaped = cna_training_data.reshape(-1, 1)\n",
    "    rna_training_data_shaped = rna_training_data.reshape(-1, 1)\n",
    "    proteome_training_data_shaped = proteome_training_data.reshape(-1, 1)\n",
    "    \n",
    "    # append cna and rna data\n",
    "    cna_rna_training_data_append = np.append(cna_training_data_shaped, rna_training_data_shaped, axis=1)\n",
    "    \n",
    "    # construct training data matrix\n",
    "    dtrain = xgb.DMatrix(cna_rna_training_data_append, label=proteome_training_data_shaped)\n",
    "    \n",
    "    print \"Training xgboost\"\n",
    "    \n",
    "    # train using default parameters\n",
    "    bst = xgb.train(dtrain=dtrain, **kwargs)\n",
    "    \n",
    "    # abundance predicitions \n",
    "    cna_validation_data_shaped = cna_validation_data.reshape(-1, 1)\n",
    "    rna_validation_data_shaped = rna_validation_data.reshape(-1, 1)\n",
    "    cna_rna_validation_data_append = np.append(cna_validation_data_shaped, rna_validation_data_shaped, axis=1)\n",
    "    dval = xgb.DMatrix(cna_rna_validation_data_append, label=proteome_training_data_shaped)\n",
    "    abundance_predictions = bst.predict(dval)\n",
    "    \n",
    "    return abundance_predictions.reshape(cna_validation_data.shape)\n",
    "\n",
    "def adaboost(cna_training_data, rna_training_data, proteome_training_data, \n",
    "             cna_validation_data, rna_validation_data, base_regressor, **kwargs):\n",
    "    \n",
    "    if base_regressor == \"linear\":\n",
    "        regressor = LinearRegression()\n",
    "    elif base_regressor == \"lasso\":\n",
    "        regressor = Lasso()\n",
    "    elif base_regressor == \"elastic_net\":\n",
    "        regressor = ElasticNet()\n",
    "    elif base_regressor == \"bayesian_ridge\":\n",
    "        regressor = BayesianRidge()\n",
    "        \n",
    "    # reshape to columns because xgboost regression can only have single numbers as labels\n",
    "    cna_training_data_shaped = cna_training_data.reshape(-1, 1)\n",
    "    rna_training_data_shaped = rna_training_data.reshape(-1, 1)\n",
    "    proteome_training_data_shaped = proteome_training_data.reshape(-1, )\n",
    "\n",
    "    # append cna and rna data\n",
    "    cna_rna_training_data_append = np.append(cna_training_data_shaped, rna_training_data_shaped, axis=1)    \n",
    "    \n",
    "    # adabosst object\n",
    "    adaboost = AdaBoostRegressor(base_estimator=regressor)\n",
    "    \n",
    "    print \"fitting adaboost with {}\".format(base_regressor)\n",
    "    \n",
    "    adaboost.fit(cna_rna_training_data_append, proteome_training_data_shaped)\n",
    "    \n",
    "    print \"predicting\"\n",
    "    \n",
    "    cna_validation_data_shaped = cna_validation_data.reshape(-1, 1)\n",
    "    rna_validation_data_shaped = rna_validation_data.reshape(-1, 1)\n",
    "    cna_rna_validation_data_append = np.append(cna_validation_data_shaped, rna_validation_data_shaped, axis=1)\n",
    "    \n",
    "    abundance_predictions = adaboost.predict(cna_rna_validation_data_append)\n",
    "    \n",
    "    return abundance_predictions.reshape(cna_validation_data.shape)\n",
    "\n",
    "def main():\n",
    "    \n",
    "    print \"Preprocessing data\"\n",
    "\n",
    "    # get training data\n",
    "    cna_training_data, rna_training_data, proteome_training_data, \\\n",
    "    cna_validation_data, rna_validation_data, proteome_validation_data, \\\n",
    "    cna_scaler, rna_scaler, proteome_scaler = preprocess_data()\n",
    "    \n",
    "    # different deep architechitures\n",
    "    deep_1 = partial(deep_non_linear_regression, activation=\"sigmoid\", num_hidden=[256])\n",
    "    deep_2 = partial(deep_non_linear_regression, activation=\"relu\", num_hidden=[256])\n",
    "    deep_3 = partial(deep_non_linear_regression, activation=\"tanh\", num_hidden=[256])\n",
    "    \n",
    "    # different xgboost parameters\n",
    "    xgboost_4 = partial(xgboost, params={\"max_depth\" : 4})\n",
    "    xgboost_6 = partial(xgboost, params={\"max_depth\" : 6})\n",
    "    xgboost_10 = partial(xgboost, params={\"max_depth\" : 10})\n",
    "    xgboost_0 = partial(xgboost, params={\"max_depth\" : 0})\n",
    "    \n",
    "    # adaboost with different base estimators\n",
    "    adaboost_linear = partial(adaboost, base_regressor=\"linear\")\n",
    "    adaboost_lasso = partial(adaboost, base_regressor=\"lasso\")\n",
    "    adaboost_elastic_net = partial(adaboost, base_regressor=\"elastic_net\")\n",
    "    adaboost_bayesian_ridge = partial(adaboost, base_regressor=\"bayesian_ridge\")\n",
    "    \n",
    "    #list of regression methods\n",
    "    regression_methods = [linear_regression, deep_1, deep_2, deep_3,\n",
    "                          xgboost_4, xgboost_6, xgboost_10, xgboost_0,\n",
    "                         adaboost_linear, adaboost_lasso, adaboost_elastic_net, adaboost_bayesian_ridge]\n",
    "    regression_method_names = [\"linear_regression\", \"sigmoid_256\", \"relu_256\", \"tanh_256\",\n",
    "                               \"xgboost_4\", \"xgboost_6\", \"xgboost_10\", \"xgboost_no_limit\",\n",
    "                              \"adaboost_linear\", \"adaboost_lasso\", \"adaboost_elastic_net\", \"adaboost_bayesian_ridge\"]\n",
    "    \n",
    "    # compute rmses\n",
    "    \n",
    "    print \"Computing rmses\"\n",
    "    rmses = np.array([mean_rmse(cna_training_data, rna_training_data, proteome_training_data,\n",
    "                                cna_validation_data, rna_validation_data, proteome_validation_data,\n",
    "                                 regression_method, num_repeats=1) for regression_method in regression_methods])\n",
    "        \n",
    "    # convert to data frame\n",
    "    rmses = pd.DataFrame(rmses, index=regression_method_names)\n",
    "    \n",
    "    print \"RMSES:\"\n",
    "    print rmses\n",
    "    \n",
    "    # TODO: compare multiple methods and save to file\n",
    "    fname = \"../results/subchallenge_2/{}.csv\".format(\"_\".join(regression_method_names))\n",
    "    print \"Saving rmses to {}\".format(fname)\n",
    "    \n",
    "    # save to file\n",
    "    rmses.to_csv(fname)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
