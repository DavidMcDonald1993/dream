{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data\n",
      "Computing rmses\n",
      "Building linear model\n",
      "Appending training matrices for linear model\n",
      "Fitting linear model\n",
      "Building deep non linear regression model\n",
      "Training deep non linear regression model\n",
      "Building deep non linear regression model\n",
      "Training deep non linear regression model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9e8fb7c30633>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-9e8fb7c30633>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Computing rmses\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     rmses = np.array([mean_rmse(cna_training_data, rna_training_data, proteome_training_data,\n\u001b[0;32m--> 201\u001b[0;31m                                  regression_method, num_repeats=1) for regression_method in regression_methods])\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"RMSES:\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-9e8fb7c30633>\u001b[0m in \u001b[0;36mmean_rmse\u001b[0;34m(cna_training_data, rna_training_data, proteome_training_data, regression_method, num_repeats, **kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     abundance_predictions = [regression_method(cna_training_data, rna_training_data, proteome_training_data, **kwargs) \n\u001b[0;32m---> 82\u001b[0;31m                              for i in range(num_repeats)]\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     rmses = np.array([rmse(abundance_prediction, proteome_training_data) \n",
      "\u001b[0;32m<ipython-input-2-9e8fb7c30633>\u001b[0m in \u001b[0;36mdeep_non_linear_regression\u001b[0;34m(cna_training_data, rna_training_data, proteome_training_data, num_hidden, dropout, activation, reg, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m     regression_model.fit([cna_training_data, rna_training_data], proteome_training_data, \n\u001b[1;32m    147\u001b[0m                          \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                          callbacks=[early_stopping])\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;31m# protein abundance predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1485\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1487\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1138\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2075\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2076\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/david/miniconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from keras.layers import Input, Dense, Concatenate, Dropout, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from fancyimpute import KNN\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "def preprocess_data():\n",
    "    \n",
    "    # import data for breast cancer datasets\n",
    "    cna_data_frame = pd.read_csv(\"../data/sub_challenge_2_3/breast_cancer_dataset/retrospective_breast_CNA_median_sort_common_gene_16884.txt\", \n",
    "                    header=0, index_col=0, sep=\"\\t\")\n",
    "    rna_data_frame = pd.read_csv(\"../data/sub_challenge_2_3/breast_cancer_dataset/retrospective_breast_rna_seq_sort_common_gene_15115.txt\", \n",
    "                    header=0, index_col=0, sep=\"\\t\")\n",
    "    proteome_data_frame = pd.read_csv(\"../data/sub_challenge_2_3/breast_cancer_dataset/retrospective_breast_proteome_filtered.txt\", \n",
    "                    header=0, index_col=0, sep=\"\\t\")\n",
    "\n",
    "    # convert rna data to numpy array to impute\n",
    "    rna_data = rna_data_frame.values\n",
    "\n",
    "    # use knn to fill in missing values in rna data\n",
    "    knn = KNN(k=5, verbose=0)\n",
    "    rna_data = knn.complete(rna_data)\n",
    "\n",
    "    # proteome data also has missing values, but I am ignoring rows with missing values for now\n",
    "    # proteome_data = knn.complete(proteome_data)\n",
    "\n",
    "    # update rna data frame with imputed data\n",
    "    rna_data_frame = pd.DataFrame(rna_data, index = rna_data_frame.index, columns = rna_data_frame.columns)\n",
    "\n",
    "    # find common proteins and patients across all datasets\n",
    "    proteins = proteome_data_frame.index.intersection(cna_data_frame.index).intersection(rna_data_frame.index)\n",
    "    patients = proteome_data_frame.columns.intersection(cna_data_frame.columns).intersection(rna_data_frame.columns)\n",
    "\n",
    "    # locate common data and return as numpy array\n",
    "    cna_data = cna_data_frame.loc[proteins, patients].values\n",
    "    rna_data = rna_data_frame.loc[proteins, patients].values\n",
    "    proteome_data = proteome_data_frame.loc[proteins, patients].values\n",
    "\n",
    "    # masks for proteins with complete data and with missing value\n",
    "    complete_proteins = proteins[~(np.isnan(proteome_data).any(axis=1))]\n",
    "    missing_value_proteins = proteins[np.isnan(proteome_data).any(axis=1)]\n",
    "\n",
    "    # use complete data as training data\n",
    "    cna_training_data = cna_data_frame.loc[complete_proteins, patients].values\n",
    "    rna_training_data = rna_data_frame.loc[complete_proteins, patients].values\n",
    "    proteome_training_data = proteome_data_frame.loc[complete_proteins, patients].values\n",
    "\n",
    "    # standard scaling\n",
    "    cna_scaler = StandardScaler()\n",
    "    rna_scaler = StandardScaler()\n",
    "    proteome_scaler = StandardScaler()\n",
    "\n",
    "    cna_training_data = cna_scaler.fit_transform(cna_training_data)\n",
    "    rna_training_data = rna_scaler.fit_transform(rna_training_data)\n",
    "    proteome_training_data = proteome_scaler.fit_transform(proteome_training_data)\n",
    "    \n",
    "    \n",
    "    # return training data scalers for inverse scaling\n",
    "    return cna_training_data, rna_training_data, proteome_training_data, cna_scaler, rna_scaler, proteome_scaler\n",
    "\n",
    "def rmse (y_pred, y_true): \n",
    "    # rsme prediction and ground truth\n",
    "    return np.sqrt(mse(y_true, y_pred))\n",
    "\n",
    "# compute mean rmse across a number of repreats\n",
    "def mean_rmse(cna_training_data, rna_training_data, proteome_training_data, regression_method, num_repeats=1, **kwargs):\n",
    "    \n",
    "    abundance_predictions = [regression_method(cna_training_data, rna_training_data, proteome_training_data, **kwargs) \n",
    "                             for i in range(num_repeats)]\n",
    "    \n",
    "    rmses = np.array([rmse(abundance_prediction, proteome_training_data) \n",
    "                      for abundance_prediction in abundance_predictions])\n",
    "\n",
    "    return rmses.mean(axis=0)\n",
    "\n",
    "def linear_regression(cna_training_data, rna_training_data, proteome_training_data, **kwargs):\n",
    "    \n",
    "    print \"Building linear model\"\n",
    "    \n",
    "    linear_model = LinearRegression()\n",
    "    \n",
    "    print \"Appending training matrices for linear model\"\n",
    "    \n",
    "    # append data for linear regression\n",
    "    cna_rna_training_data_append = np.append(cna_training_data, rna_training_data, axis=1)\n",
    "    \n",
    "    print \"Fitting linear model\"\n",
    "    \n",
    "    linear_model.fit(cna_rna_training_data_append, proteome_training_data)\n",
    "    \n",
    "    abundance_predictions = linear_model.predict(cna_rna_training_data_append)\n",
    "    \n",
    "    return abundance_predictions\n",
    "\n",
    "# construct model\n",
    "def build_deep_regression_model(num_samples, num_hidden, dropout, activation, reg):\n",
    "    \n",
    "    regulariser = l2(reg)\n",
    "\n",
    "    cna = Input(shape=(num_samples,))\n",
    "    rna = Input(shape=(num_samples,))\n",
    "\n",
    "    y = Concatenate()([cna, rna])\n",
    "\n",
    "    for h in num_hidden:\n",
    "        y = Dense(h, activation=activation, kernel_regularizer=regulariser)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Dropout(dropout)(y)\n",
    "\n",
    "    y = Dense(num_samples, kernel_regularizer=regulariser)(y)\n",
    "\n",
    "    deep_non_linear_regression_model = Model([cna, rna], y)\n",
    "    deep_non_linear_regression_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    \n",
    "    return deep_non_linear_regression_model\n",
    "\n",
    "def deep_non_linear_regression(cna_training_data, rna_training_data, proteome_training_data,\n",
    "                               num_hidden=[128], dropout=0.1, activation=\"relu\", reg=1e-3, **kwargs):\n",
    "    \n",
    "    print \"Building deep non linear regression model\"\n",
    "    \n",
    "    # dimensionality of data\n",
    "    num_proteins, num_samples = cna_training_data.shape\n",
    "     \n",
    "    # build model\n",
    "    regression_model = build_deep_regression_model(num_samples, num_hidden, dropout, activation, reg)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor=\"loss\", patience=1000, min_delta=0, )\n",
    "    \n",
    "    print \"Training deep non linear regression model\"\n",
    "\n",
    "    # train model\n",
    "    regression_model.fit([cna_training_data, rna_training_data], proteome_training_data, \n",
    "                         verbose=0, epochs=10000, batch_size=128, shuffle=True, validation_split=0.0,\n",
    "                         callbacks=[early_stopping])\n",
    "\n",
    "    # protein abundance predictions\n",
    "    abundance_predictions = regression_model.predict([cna_training_data, rna_training_data])\n",
    "    \n",
    "    return abundance_predictions\n",
    "\n",
    "def xgboost(cna_training_data, rna_training_data, proteome_training_data, **kwargs):\n",
    "    \n",
    "    print \"Reshaping training matrices for xgboost\"\n",
    "    \n",
    "    # reshape to columns because xgboost regression can only have single numbers as labels\n",
    "    cna_training_data_shaped = cna_training_data.reshape(-1, 1)\n",
    "    rna_training_data_shaped = rna_training_data.reshape(-1, 1)\n",
    "    proteome_training_data_shaped = proteome_training_data.reshape(-1, 1)\n",
    "    \n",
    "    # append cna and rna data\n",
    "    cna_rna_training_data_append = np.append(cna_training_data_shaped, rna_training_data_shaped, axis=1)\n",
    "    \n",
    "    # construct training data matrix\n",
    "    dtrain = xgb.DMatrix(cna_rna_training_data_append, label=proteome_training_data_shaped)\n",
    "    \n",
    "    print \"Training xgboost\"\n",
    "    \n",
    "    # train using default parameters\n",
    "    bst = xgb.train(params={}, dtrain=dtrain)\n",
    "    \n",
    "    # abundance predicitions \n",
    "    abundance_predictions = bst.predict(dtrain)\n",
    "    \n",
    "    return abundance_predictions.reshape(proteome_training_data.shape)\n",
    "\n",
    "def main():\n",
    "    \n",
    "    print \"Preprocessing data\"\n",
    "\n",
    "    # get training data\n",
    "    cna_training_data, rna_training_data, proteome_training_data, cna_scaler, rna_scaler, proteome_scaler = preprocess_data()\n",
    "    \n",
    "    # different deep architechitures\n",
    "    deep_1 = partial(deep_non_linear_regression, acitvation=\"sigmoid\", num_hidden=[256])\n",
    "    deep_2 = partial(deep_non_linear_regression, activation=\"sigmoid\", num_hidden=[256], dropout=0.2)\n",
    "    deep_3 = partial(deep_non_linear_regression, activation=\"sigmoid\", num_hidden=[256], dropout=0.5)\n",
    "    \n",
    "    #list of regression methods\n",
    "    regression_methods = [linear_regression, deep_1, deep_2, deep_3, xgboost]\n",
    "    regression_method_names = [\"linear_regression\", \"sigmoid_01_dropout\", \"sigmoid_02_dropout\",\n",
    "                               \"sigmoid_05_dropoout\", \"xgboost\"]\n",
    "    \n",
    "    # compute rmses\n",
    "    \n",
    "    print \"Computing rmses\"\n",
    "    rmses = np.array([mean_rmse(cna_training_data, rna_training_data, proteome_training_data,\n",
    "                                 regression_method, num_repeats=1) for regression_method in regression_methods])\n",
    "    \n",
    "    print \"RMSES:\"\n",
    "    print rmses\n",
    "    \n",
    "    # TODO: compare multiple methods and save to file\n",
    "    fname = \"../results/subchallenge_2/{}.csv\".format(\"_\".join(regression_method_names))\n",
    "    print \"Saving rmses to {}\".format(fname)\n",
    "    \n",
    "    # save to file\n",
    "    np.savetxt(X=rmses, fname=fname, delimiter=\",\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
