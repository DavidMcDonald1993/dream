{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "ERROR (theano.gpuarray): Could not initialize pygpu, support disabled\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/david/miniconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 179, in <module>\n",
      "    use(config.device)\n",
      "  File \"/home/david/miniconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 166, in use\n",
      "    init_dev(device, preallocate=preallocate)\n",
      "  File \"/home/david/miniconda2/lib/python2.7/site-packages/theano/gpuarray/__init__.py\", line 65, in init_dev\n",
      "    sched=config.gpuarray.sched)\n",
      "  File \"pygpu/gpuarray.pyx\", line 634, in pygpu.gpuarray.init (pygpu/gpuarray.c:9424)\n",
      "  File \"pygpu/gpuarray.pyx\", line 584, in pygpu.gpuarray.pygpu_init (pygpu/gpuarray.c:9115)\n",
      "  File \"pygpu/gpuarray.pyx\", line 1057, in pygpu.gpuarray.GpuContext.__cinit__ (pygpu/gpuarray.c:13417)\n",
      "GpuArrayException: cuInit: CUDA_ERROR_UNKNOWN: unknown error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from keras.layers import Input, Dense, Concatenate, Dropout, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from fancyimpute import KNN\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "def preprocess_data():\n",
    "    \n",
    "    # import data for breast cancer datasets\n",
    "    cna_data_frame = pd.read_csv(\"../data/sub_challenge_2_3/breast_cancer_dataset/retrospective_breast_CNA_median_sort_common_gene_16884.txt\", \n",
    "                    header=0, index_col=0, sep=\"\\t\")\n",
    "    rna_data_frame = pd.read_csv(\"../data/sub_challenge_2_3/breast_cancer_dataset/retrospective_breast_rna_seq_sort_common_gene_15115.txt\", \n",
    "                    header=0, index_col=0, sep=\"\\t\")\n",
    "    proteome_data_frame = pd.read_csv(\"../data/sub_challenge_2_3/breast_cancer_dataset/retrospective_breast_proteome_filtered.txt\", \n",
    "                    header=0, index_col=0, sep=\"\\t\")\n",
    "\n",
    "    # convert rna data to numpy array to impute\n",
    "    rna_data = rna_data_frame.values\n",
    "\n",
    "    # use knn to fill in missing values in rna data\n",
    "    knn = KNN(k=5, verbose=0)\n",
    "    rna_data = knn.complete(rna_data)\n",
    "\n",
    "    # proteome data also has missing values, but I am ignoring rows with missing values for now\n",
    "    # proteome_data = knn.complete(proteome_data)\n",
    "\n",
    "    # update rna data frame with imputed data\n",
    "    rna_data_frame = pd.DataFrame(rna_data, index = rna_data_frame.index, columns = rna_data_frame.columns)\n",
    "\n",
    "    # find common proteins and patients across all datasets\n",
    "    proteins = proteome_data_frame.index.intersection(cna_data_frame.index).intersection(rna_data_frame.index)\n",
    "    patients = proteome_data_frame.columns.intersection(cna_data_frame.columns).intersection(rna_data_frame.columns)\n",
    "\n",
    "    # locate common data and return as numpy array\n",
    "    cna_data = cna_data_frame.loc[proteins, patients].values\n",
    "    rna_data = rna_data_frame.loc[proteins, patients].values\n",
    "    proteome_data = proteome_data_frame.loc[proteins, patients].values\n",
    "\n",
    "    # masks for proteins with complete data and with missing value\n",
    "    complete_proteins = proteins[~(np.isnan(proteome_data).any(axis=1))]\n",
    "    missing_value_proteins = proteins[np.isnan(proteome_data).any(axis=1)]\n",
    "\n",
    "    # use complete data as training data\n",
    "    cna_training_data = cna_data_frame.loc[complete_proteins, patients].values\n",
    "    rna_training_data = rna_data_frame.loc[complete_proteins, patients].values\n",
    "    proteome_training_data = proteome_data_frame.loc[complete_proteins, patients].values\n",
    "\n",
    "    # standard scaling\n",
    "    cna_scaler = StandardScaler()\n",
    "    rna_scaler = StandardScaler()\n",
    "    proteome_scaler = StandardScaler()\n",
    "\n",
    "    cna_training_data = cna_scaler.fit_transform(cna_training_data)\n",
    "    rna_training_data = rna_scaler.fit_transform(rna_training_data)\n",
    "    proteome_training_data = proteome_scaler.fit_transform(proteome_training_data)\n",
    "    \n",
    "    \n",
    "    # return training data scalers for inverse scaling\n",
    "    return cna_training_data, rna_training_data, proteome_training_data, cna_scaler, rna_scaler, proteome_scaler\n",
    "\n",
    "def rmse (y_pred, y_true): \n",
    "    # rsme prediction and ground truth\n",
    "    return np.sqrt(mse(y_true, y_pred))\n",
    "\n",
    "# compute mean rmse across a number of repreats\n",
    "def mean_rmse(cna_training_data, rna_training_data, proteome_training_data, regression_method, num_repeats=1, **kwargs):\n",
    "    \n",
    "    abundance_predictions = [regression_method(cna_training_data, rna_training_data, proteome_training_data, **kwargs) \n",
    "                             for i in range(num_repeats)]\n",
    "    \n",
    "    rmses = np.array([rmse(abundance_prediction, proteome_training_data) \n",
    "                      for abundance_prediction in abundance_predictions])\n",
    "\n",
    "    return rmses.mean(axis=0)\n",
    "\n",
    "def linear_regression(cna_training_data, rna_training_data, proteome_training_data, **kwargs):\n",
    "    \n",
    "    print \"Building linear model\"\n",
    "    \n",
    "    linear_model = LinearRegression()\n",
    "    \n",
    "    print \"Appending training matrices for linear model\"\n",
    "    \n",
    "    # append data for linear regression\n",
    "    cna_rna_training_data_append = np.append(cna_training_data, rna_training_data, axis=1)\n",
    "    \n",
    "    print \"Fitting linear model\"\n",
    "    \n",
    "    linear_model.fit(cna_rna_training_data_append, proteome_training_data)\n",
    "    \n",
    "    abundance_predictions = linear_model.predict(cna_rna_training_data_append)\n",
    "    \n",
    "    return abundance_predictions\n",
    "\n",
    "# construct model\n",
    "def build_deep_regression_model(num_samples, num_hidden, dropout, activation, reg):\n",
    "    \n",
    "    regulariser = l2(reg)\n",
    "\n",
    "    cna = Input(shape=(num_samples,))\n",
    "    rna = Input(shape=(num_samples,))\n",
    "\n",
    "    y = Concatenate()([cna, rna])\n",
    "\n",
    "    for h in num_hidden:\n",
    "        y = Dense(h, activation=activation, kernel_regularizer=regulariser)(y)\n",
    "        y = BatchNormalization()(y)\n",
    "        y = Dropout(dropout)(y)\n",
    "\n",
    "    y = Dense(num_samples, kernel_regularizer=regulariser)(y)\n",
    "\n",
    "    deep_non_linear_regression_model = Model([cna, rna], y)\n",
    "    deep_non_linear_regression_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "    \n",
    "    return deep_non_linear_regression_model\n",
    "\n",
    "def deep_non_linear_regression(cna_training_data, rna_training_data, proteome_training_data,\n",
    "                               num_hidden=[128], dropout=0.1, activation=\"relu\", reg=1e-3, **kwargs):\n",
    "    \n",
    "    print \"Building deep non linear regression model\"\n",
    "    \n",
    "    # dimensionality of data\n",
    "    num_proteins, num_samples = cna_training_data.shape\n",
    "     \n",
    "    # build model\n",
    "    regression_model = build_deep_regression_model(num_samples, num_hidden, dropout, activation, reg)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor=\"loss\", patience=1000, min_delta=0, )\n",
    "    \n",
    "    print \"Training deep non linear regression model\"\n",
    "\n",
    "    # train model\n",
    "    regression_model.fit([cna_training_data, rna_training_data], proteome_training_data, \n",
    "                         verbose=0, epochs=10000, batch_size=128, shuffle=True, validation_split=0.0,\n",
    "                         callbacks=[early_stopping])\n",
    "\n",
    "    # protein abundance predictions\n",
    "    abundance_predictions = regression_model.predict([cna_training_data, rna_training_data])\n",
    "    \n",
    "    return abundance_predictions\n",
    "\n",
    "def xgboost(cna_training_data, rna_training_data, proteome_training_data, **kwargs):\n",
    "    \n",
    "    print \"Reshaping training matrices for xgboost\"\n",
    "    \n",
    "    # reshape to columns because xgboost regression can only have single numbers as labels\n",
    "    cna_training_data_shaped = cna_training_data.reshape(-1, 1)\n",
    "    rna_training_data_shaped = rna_training_data.reshape(-1, 1)\n",
    "    proteome_training_data_shaped = proteome_training_data.reshape(-1, 1)\n",
    "    \n",
    "    # append cna and rna data\n",
    "    cna_rna_training_data_append = np.append(cna_training_data_shaped, rna_training_data_shaped, axis=1)\n",
    "    \n",
    "    # construct training data matrix\n",
    "    dtrain = xgb.DMatrix(cna_rna_training_data_append, label=proteome_training_data_shaped)\n",
    "    \n",
    "    print \"Training xgboost\"\n",
    "    \n",
    "    # train using default parameters\n",
    "    bst = xgb.train(params={}, dtrain=dtrain)\n",
    "    \n",
    "    # abundance predicitions \n",
    "    abundance_predictions = bst.predict(dtrain)\n",
    "    \n",
    "    return abundance_predictions.reshape(proteome_training_data.shape)\n",
    "\n",
    "def main():\n",
    "    \n",
    "    print \"Preprocessing data\"\n",
    "\n",
    "    # get training data\n",
    "    cna_training_data, rna_training_data, proteome_training_data, cna_scaler, rna_scaler, proteome_scaler = preprocess_data()\n",
    "    \n",
    "    # different deep architechitures\n",
    "    deep_1 = deep_non_linear_regression\n",
    "    deep_2 = partial(deep_non_linear_regression, num_hidden=[128, 64])\n",
    "    deep_3 = partial(deep_non_linear_regression, num_hidden=[256, 128, 64])\n",
    "    \n",
    "    #list of regression methods\n",
    "    regression_methods = [linear_regression, deep_1, deep_2, deep_3, xgboost]\n",
    "    regression_method_names = [\"linear_regression\", \"deep_128\", \"deep_128_64\", \"deep_256_128_64\", \"xgboost\"]\n",
    "    \n",
    "    # compute rmses\n",
    "    \n",
    "    print \"Computing rmses\"\n",
    "    rmses = np.array([mean_rmse(cna_training_data, rna_training_data, proteome_training_data,\n",
    "                                 regression_method, num_repeats=1) for regression_method in regression_methods])\n",
    "    \n",
    "    print \"RMSES:\"\n",
    "    print rmses\n",
    "    \n",
    "    # TODO: compare multiple methods and save to file\n",
    "    fname = \"../results/subchallenge_2/{}.csv\".format(\"_\".join(regression_method_names))\n",
    "    print \"Saving rmses to {}\".format(fname)\n",
    "    \n",
    "    # save to file\n",
    "    np.savetxt(X=rmses, fname=fname, delimiter=\",\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
